{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import get_Xy, preprocess, model_generator, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/predictive_maintenance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = get_Xy(df, 'Failure Type', binary=['No Failure'], drop_cols=['UDI', 'Product ID'])\n",
    "X_train, X_test, y_train, y_test = get_Xy(df, 'Target', drop_cols=['UDI', 'Product ID', 'Failure Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = preprocess(X_train, y_train, label_cols=['Target'])\n",
    "preprocessor = preprocess(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;,\n",
       "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
       "                                               feature_name_combiner=&lt;function name_feat at 0x17f5dba30&gt;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Type&#x27;]),\n",
       "                                (&#x27;ss_encode_X&#x27;, StandardScaler(with_mean=False),\n",
       "                                 [&#x27;Torque [Nm]&#x27;]),\n",
       "                                (&#x27;minmax_encode_X&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;Air temperature [K]&#x27;,\n",
       "                                  &#x27;Process temperature [K]&#x27;,\n",
       "                                  &#x27;Rotational speed [rpm]&#x27;,\n",
       "                                  &#x27;Tool wear [min]&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;,\n",
       "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
       "                                               feature_name_combiner=&lt;function name_feat at 0x17f5dba30&gt;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Type&#x27;]),\n",
       "                                (&#x27;ss_encode_X&#x27;, StandardScaler(with_mean=False),\n",
       "                                 [&#x27;Torque [Nm]&#x27;]),\n",
       "                                (&#x27;minmax_encode_X&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;Air temperature [K]&#x27;,\n",
       "                                  &#x27;Process temperature [K]&#x27;,\n",
       "                                  &#x27;Rotational speed [rpm]&#x27;,\n",
       "                                  &#x27;Tool wear [min]&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">ohe</label><div class=\"sk-toggleable__content \"><pre>[&#x27;Type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(dtype=&#x27;int&#x27;,\n",
       "              feature_name_combiner=&lt;function name_feat at 0x17f5dba30&gt;,\n",
       "              handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">ss_encode_X</label><div class=\"sk-toggleable__content \"><pre>[&#x27;Torque [Nm]&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler(with_mean=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">minmax_encode_X</label><div class=\"sk-toggleable__content \"><pre>[&#x27;Air temperature [K]&#x27;, &#x27;Process temperature [K]&#x27;, &#x27;Rotational speed [rpm]&#x27;, &#x27;Tool wear [min]&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">remainder</label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">passthrough</label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('ohe',\n",
       "                                 OneHotEncoder(dtype='int',\n",
       "                                               feature_name_combiner=<function name_feat at 0x17f5dba30>,\n",
       "                                               handle_unknown='ignore',\n",
       "                                               sparse_output=False),\n",
       "                                 ['Type']),\n",
       "                                ('ss_encode_X', StandardScaler(with_mean=False),\n",
       "                                 ['Torque [Nm]']),\n",
       "                                ('minmax_encode_X', MinMaxScaler(),\n",
       "                                 ['Air temperature [K]',\n",
       "                                  'Process temperature [K]',\n",
       "                                  'Rotational speed [rpm]',\n",
       "                                  'Tool wear [min]'])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually preprocessing the data so that other group members can use it to compare output from their pipelines\n",
    "cols = dict(zip(range(8), ['H', 'L', 'M'] + list(df.columns[3:])))\n",
    "\n",
    "X_train_transformed = pd.DataFrame(preprocessor[1].fit_transform(X_train))\n",
    "X_train_transformed = X_train_transformed.rename(columns=cols)\n",
    "X_train_transformed.to_pickle(\"X_train_transformed.pickle\")\n",
    "\n",
    "X_test_transformed = pd.DataFrame(preprocessor[1].transform(X_test))\n",
    "X_test_transformed = X_test_transformed.rename(columns=cols)\n",
    "X_test_transformed.to_pickle(\"X_test_transformed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO LOAD PROCESSED DATA\n",
    "# X_train_transformed = pd.read_pickle(\"X_train_transformed.pickle\")\n",
    "# X_test_transformed = pd.read_pickle(\"X_test_transformed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.736597</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.176950</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.357693</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.183353</td>\n",
       "      <td>0.059289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.035359</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.309080</td>\n",
       "      <td>0.703557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319391</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.145518</td>\n",
       "      <td>0.039526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.476137</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.253783</td>\n",
       "      <td>0.628458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.988807</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.123981</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.497941</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.135623</td>\n",
       "      <td>0.802372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.367711</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.121653</td>\n",
       "      <td>0.110672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.409550</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.109430</td>\n",
       "      <td>0.023715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.808489</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.159488</td>\n",
       "      <td>0.715415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        H    L    M  Air temperature [K]  Process temperature [K]  \\\n",
       "0     0.0  1.0  0.0             3.736597                 0.554348   \n",
       "1     0.0  1.0  0.0             4.357693                 0.434783   \n",
       "2     0.0  1.0  0.0             3.035359                 0.543478   \n",
       "3     0.0  1.0  0.0             5.319391                 0.445652   \n",
       "4     0.0  1.0  0.0             3.476137                 0.402174   \n",
       "...   ...  ...  ...                  ...                      ...   \n",
       "7995  0.0  1.0  0.0             4.988807                 0.641304   \n",
       "7996  0.0  1.0  0.0             4.497941                 0.782609   \n",
       "7997  0.0  1.0  0.0             4.367711                 0.445652   \n",
       "7998  0.0  1.0  0.0             5.409550                 0.358696   \n",
       "7999  0.0  1.0  0.0             4.808489                 0.391304   \n",
       "\n",
       "      Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  \n",
       "0                   0.679012     0.176950         0.739130  \n",
       "1                   0.629630     0.183353         0.059289  \n",
       "2                   0.419753     0.309080         0.703557  \n",
       "3                   0.604938     0.145518         0.039526  \n",
       "4                   0.345679     0.253783         0.628458  \n",
       "...                      ...          ...              ...  \n",
       "7995                0.580247     0.123981         0.454545  \n",
       "7996                0.765432     0.135623         0.802372  \n",
       "7997                0.444444     0.121653         0.110672  \n",
       "7998                0.493827     0.109430         0.023715  \n",
       "7999                0.543210     0.159488         0.715415  \n",
       "\n",
       "[8000 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing pipeline to file\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.989 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.980 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.983 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.980 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.985 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.970 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.971 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.972 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.973 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.964 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.964 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.959 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.960 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.955 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.954 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.951 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.961 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.940 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.945 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.936 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.942 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.935 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.943 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.933 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.939 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.932 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.939 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.989 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.980 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.983 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.980 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.985 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.970 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.971 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.972 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.973 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.964 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.964 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.959 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.960 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.955 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.954 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.951 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.961 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.940 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.945 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.936 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.942 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.935 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.943 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.933 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.939 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.932 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.939 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.989 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.980 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.983 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.980 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.985 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.970 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.971 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.972 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.973 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.964 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.964 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.959 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.960 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.955 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.954 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.951 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.961 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.940 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.945 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.936 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.942 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.935 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.943 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.933 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.939 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.932 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.939 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.990 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.989 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.991 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.990 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.991 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.980 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.983 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.984 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.980 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.985 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.984 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.976 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.977 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.970 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.971 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.973 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.972 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.973 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.964 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.967 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.964 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.959 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.962 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.960 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.967 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.955 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.954 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.951 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.961 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.948 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.940 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.951 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.953 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.945 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.936 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.942 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.935 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.943 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.933 total time=   0.1s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.939 total time=   0.1s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.932 total time=   0.1s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.946 total time=   0.1s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.939 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.950 total time=   0.0s\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=1, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=3, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=3, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.907 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=5, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=7, weights=uniform;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=7, weights=distance;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=9, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=9, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=11, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=13, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=13, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=15, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=17, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=17, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.832 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=10, n_neighbors=19, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=1, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=1, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.907 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=17, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=17, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.832 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=1, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=3, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=3, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.907 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=5, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=7, weights=uniform;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=7, weights=distance;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=17, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=17, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.832 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=19, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=1, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=3, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=3, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.907 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=5, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=7, weights=uniform;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=7, weights=distance;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=9, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=9, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=11, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=13, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=13, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=15, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=17, weights=uniform;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=17, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.832 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=uniform;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END leaf_size=500, n_neighbors=19, weights=distance;, score=0.811 total time=   0.0s\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.995 total time=   0.5s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.998 total time=   0.5s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.999 total time=   0.5s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.995 total time=   0.5s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.997 total time=   0.5s\n",
      "[CV 1/5] END ..................n_estimators=128;, score=0.995 total time=   0.6s\n",
      "[CV 2/5] END ..................n_estimators=128;, score=0.997 total time=   0.6s\n",
      "[CV 3/5] END ..................n_estimators=128;, score=0.998 total time=   0.6s\n",
      "[CV 4/5] END ..................n_estimators=128;, score=0.996 total time=   0.6s\n",
      "[CV 5/5] END ..................n_estimators=128;, score=0.997 total time=   0.8s\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.916 total time=   0.1s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.916 total time=   0.1s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.868 total time=   0.1s\n",
      "[CV 1/5] END ..................n_estimators=128;, score=0.888 total time=   0.1s\n",
      "[CV 2/5] END ..................n_estimators=128;, score=0.879 total time=   0.1s\n",
      "[CV 3/5] END ..................n_estimators=128;, score=0.963 total time=   0.1s\n",
      "[CV 4/5] END ..................n_estimators=128;, score=0.925 total time=   0.1s\n",
      "[CV 5/5] END ..................n_estimators=128;, score=0.858 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adellehousker/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/adellehousker/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .....................kernel=linear;, score=0.821 total time=   1.5s\n",
      "[CV 2/5] END .....................kernel=linear;, score=0.829 total time=   1.5s\n",
      "[CV 3/5] END .....................kernel=linear;, score=0.825 total time=   1.5s\n",
      "[CV 4/5] END .....................kernel=linear;, score=0.821 total time=   1.6s\n",
      "[CV 5/5] END .....................kernel=linear;, score=0.836 total time=   1.5s\n",
      "[CV 1/5] END .......................kernel=poly;, score=0.864 total time=   1.3s\n",
      "[CV 2/5] END .......................kernel=poly;, score=0.871 total time=   1.3s\n",
      "[CV 3/5] END .......................kernel=poly;, score=0.870 total time=   1.3s\n",
      "[CV 4/5] END .......................kernel=poly;, score=0.863 total time=   1.3s\n",
      "[CV 5/5] END .......................kernel=poly;, score=0.882 total time=   1.3s\n",
      "[CV 1/5] END ........................kernel=rbf;, score=0.861 total time=   1.5s\n",
      "[CV 2/5] END ........................kernel=rbf;, score=0.863 total time=   1.5s\n",
      "[CV 3/5] END ........................kernel=rbf;, score=0.867 total time=   1.5s\n",
      "[CV 4/5] END ........................kernel=rbf;, score=0.857 total time=   1.4s\n",
      "[CV 5/5] END ........................kernel=rbf;, score=0.872 total time=   1.4s\n",
      "[CV 1/5] END ....................kernel=sigmoid;, score=0.213 total time=   2.7s\n",
      "[CV 2/5] END ....................kernel=sigmoid;, score=0.203 total time=   2.7s\n",
      "[CV 3/5] END ....................kernel=sigmoid;, score=0.207 total time=   2.7s\n",
      "[CV 4/5] END ....................kernel=sigmoid;, score=0.220 total time=   2.7s\n",
      "[CV 5/5] END ....................kernel=sigmoid;, score=0.215 total time=   2.7s\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .....................kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END .....................kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END .....................kernel=linear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END .....................kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END .....................kernel=linear;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END .......................kernel=poly;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END .......................kernel=poly;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END .......................kernel=poly;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END .......................kernel=poly;, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END .......................kernel=poly;, score=0.802 total time=   0.0s\n",
      "[CV 1/5] END ........................kernel=rbf;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END ........................kernel=rbf;, score=0.785 total time=   0.0s\n",
      "[CV 3/5] END ........................kernel=rbf;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END ........................kernel=rbf;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END ........................kernel=rbf;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ....................kernel=sigmoid;, score=0.234 total time=   0.0s\n",
      "[CV 2/5] END ....................kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 3/5] END ....................kernel=sigmoid;, score=0.140 total time=   0.0s\n",
      "[CV 4/5] END ....................kernel=sigmoid;, score=0.224 total time=   0.0s\n",
      "[CV 5/5] END ....................kernel=sigmoid;, score=0.226 total time=   0.0s\n",
      "<class 'imblearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipelines = pd.read_pickle(\"pipeline.pickle\")\n",
    "    print(\"reading pipeline from file\")\n",
    "except:\n",
    "    print(\"writing pipeline to file\")\n",
    "    pipelines = model_generator(X_train, y_train, preprocessor, models=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}, 'SVM': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}, 'SVM': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'over-sampler', 'classifier'])\n",
      "-----------------\n",
      "over-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}, 'SVM': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n'}, 'Naive Bayes': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.89      1928\\n    positive       0.14      0.79      0.24        72\\n\\n    accuracy                           0.81      2000\\n   macro avg       0.56      0.80      0.57      2000\\nweighted avg       0.96      0.81      0.87      2000\\n'}}\n",
      "dict_keys(['preprocessor', 'under-sampler', 'classifier'])\n",
      "-----------------\n",
      "under-sampler\n",
      "{'Logistic Regression': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.78      0.87      1928\\n    positive       0.11      0.75      0.20        72\\n\\n    accuracy                           0.78      2000\\n   macro avg       0.55      0.77      0.53      2000\\nweighted avg       0.96      0.78      0.85      2000\\n'}, 'KNN': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.90      1928\\n    positive       0.15      0.88      0.26        72\\n\\n    accuracy                           0.82      2000\\n   macro avg       0.57      0.85      0.58      2000\\nweighted avg       0.96      0.82      0.87      2000\\n'}, 'Decision Tree': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.25      0.96      0.40        72\\n\\n    accuracy                           0.90      2000\\n   macro avg       0.62      0.93      0.67      2000\\nweighted avg       0.97      0.90      0.92      2000\\n'}, 'Random Forest': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.24      0.90      0.38        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.62      0.90      0.66      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'Extremely Random Trees': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.87      0.93      1928\\n    positive       0.21      0.89      0.34        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.88      0.63      2000\\nweighted avg       0.97      0.87      0.91      2000\\n'}, 'Gradient Boosting': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       1.00      0.89      0.94      1928\\n    positive       0.23      0.90      0.37        72\\n\\n    accuracy                           0.89      2000\\n   macro avg       0.61      0.90      0.65      2000\\nweighted avg       0.97      0.89      0.92      2000\\n'}, 'AdaBoost': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.87      0.93      1928\\n    positive       0.20      0.85      0.32        72\\n\\n    accuracy                           0.87      2000\\n   macro avg       0.60      0.86      0.63      2000\\nweighted avg       0.96      0.87      0.91      2000\\n'}, 'SVM': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.86      0.92      1928\\n    positive       0.16      0.75      0.27        72\\n\\n    accuracy                           0.85      2000\\n   macro avg       0.58      0.80      0.59      2000\\nweighted avg       0.96      0.85      0.90      2000\\n'}, 'Naive Bayes': {'over-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.89      1928\\n    positive       0.14      0.79      0.24        72\\n\\n    accuracy                           0.81      2000\\n   macro avg       0.56      0.80      0.57      2000\\nweighted avg       0.96      0.81      0.87      2000\\n', 'under-sampler': '              precision    recall  f1-score   support\\n\\n    negative       0.99      0.82      0.89      1928\\n    positive       0.14      0.79      0.24        72\\n\\n    accuracy                           0.81      2000\\n   macro avg       0.56      0.80      0.57      2000\\nweighted avg       0.96      0.81      0.87      2000\\n'}}\n"
     ]
    }
   ],
   "source": [
    "evals = evaluate(pipelines, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['over-sampler', 'under-sampler'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals['Logistic Regression'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression -----------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "KNN ---------------------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "Decision Tree -----------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "Random Forest -----------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "Extremely Random Trees --------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "Gradient Boosting -------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "AdaBoost ----------------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "SVM ---------------------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n",
      "Naive Bayes -------------------------------------------------\n",
      "\n",
      "over-sampler  |  under-sampler  |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, samplers in evals.items():\n",
    "    print(model, '-' * (60 - len(model)))\n",
    "    print()\n",
    "    for sample, report in samplers.items():\n",
    "        print(sample, end=\"  |  \") \n",
    "        print(report) \n",
    "    print(\"\\n\")\n",
    "    # print(f\"{e['model']} ({e['sample']})\", '-' * (45 - len(e['model'])), \"|\")\n",
    "    # print(e['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- WITHOUT OVERSAMPLING ---\n",
    "\n",
    "Logistic Regression -----------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.96      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "KNN ---------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.96      0.89      0.93        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           0.99      2000\n",
    "   macro avg       0.98      0.95      0.96      2000\n",
    "weighted avg       0.99      0.99      0.99      2000\n",
    "\n",
    "Decision Tree -----------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.93      0.93      0.93        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           0.99      2000\n",
    "   macro avg       0.97      0.97      0.97      2000\n",
    "weighted avg       0.99      0.99      0.99      2000\n",
    "\n",
    "Random Forest -----------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.96      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "Extremely Random Trees --------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.96      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "Gradient Boosting -------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.96      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "AdaBoost ----------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.95      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.97      0.97      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "SVM ---------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.96      0.95        76\n",
    "    positive       1.00      1.00      1.00      1924\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- WITH OVERSAMPLING ---\n",
    "\n",
    "Logistic Regression -----------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.95      0.97      0.96        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.97      0.98      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "KNN ---------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.89      0.92      0.90        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           0.99      2000\n",
    "   macro avg       0.94      0.96      0.95      2000\n",
    "weighted avg       0.99      0.99      0.99      2000\n",
    "\n",
    "Decision Tree -----------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.92      0.93      0.92        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           0.99      2000\n",
    "   macro avg       0.96      0.96      0.96      2000\n",
    "weighted avg       0.99      0.99      0.99      2000\n",
    "\n",
    "Random Forest -----------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.96      0.97      0.97        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.98      0.99      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "Extremely Random Trees --------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.96      0.97      0.97        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.98      0.99      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "Gradient Boosting -------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.92      0.97      0.95        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.96      0.98      0.97      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "AdaBoost ----------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.87      0.97      0.92        71\n",
    "    positive       1.00      0.99      1.00      1929\n",
    "\n",
    "    accuracy                           0.99      2000\n",
    "   macro avg       0.94      0.98      0.96      2000\n",
    "weighted avg       0.99      0.99      0.99      2000\n",
    "\n",
    "SVM ---------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.96      0.97      0.97        71\n",
    "    positive       1.00      1.00      1.00      1929\n",
    "\n",
    "    accuracy                           1.00      2000\n",
    "   macro avg       0.98      0.99      0.98      2000\n",
    "weighted avg       1.00      1.00      1.00      2000\n",
    "\n",
    "Naive Bayes -------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.09      0.18      0.12        71\n",
    "    positive       0.97      0.93      0.95      1929\n",
    "\n",
    "    accuracy                           0.90      2000\n",
    "   macro avg       0.53      0.56      0.53      2000\n",
    "weighted avg       0.94      0.90      0.92      2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification\n",
    "X_train, X_test, y_train, y_test = get_Xy(df, 'Target', drop_cols=['UDI', 'Product ID', 'Failure Type'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
