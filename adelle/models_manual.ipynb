{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_manual import get_Xy, model_generator, evaluate\n",
    "\n",
    "from utils import _find_scaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Import RandomOverSampler from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/predictive_maintenance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_Xy(df, 'Target', drop_cols=['UDI', 'Product ID', 'Failure Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard, minmax = _find_scaler(X_train)\n",
    "\n",
    "# OneHotEncoder for 'Type' feature\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train[[\"Type\"]])\n",
    "X_train_type_encoded = ohe.transform(X_train[[\"Type\"]])\n",
    "X_test_type_encoded = ohe.transform(X_test[[\"Type\"]])\n",
    "\n",
    "# StandardScaler for 'Torque [Nm]'\n",
    "s_scaler = StandardScaler().fit(X_train[standard])\n",
    "X_train_continuous_norm_scaled = s_scaler.transform(X_train[standard])\n",
    "X_test_continuous_norm_scaled = s_scaler.transform(X_test[standard])\n",
    "\n",
    "# MinMaxScaler for continuous features\n",
    "mm_scaler = MinMaxScaler().fit(X_train[minmax])\n",
    "X_train_continuous_scaled = mm_scaler.transform(X_train[minmax])\n",
    "X_test_continuous_scaled = mm_scaler.transform(X_test[minmax])\n",
    "\n",
    "# Combine encoded categorical features and scaled continuous features\n",
    "X_train_processed = pd.concat([pd.DataFrame(X_train_type_encoded, columns=['L', 'M', 'H']), pd.DataFrame(X_train_continuous_norm_scaled, columns=standard), pd.DataFrame(X_train_continuous_scaled, columns=minmax)], axis=1)\n",
    "X_test_processed = pd.concat([pd.DataFrame(X_test_type_encoded, columns=['L', 'M', 'H']), pd.DataFrame(X_test_continuous_norm_scaled, columns=standard), pd.DataFrame(X_test_continuous_scaled, columns=minmax)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>H</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666192</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.114522</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.823706</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.098814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     L    M    H  Torque [Nm]  Air temperature [K]  Process temperature [K]  \\\n",
       "0  0.0  1.0  0.0     0.666192             0.478261                 0.567901   \n",
       "1  0.0  1.0  0.0    -0.823706             0.402174                 0.407407   \n",
       "\n",
       "   Rotational speed [rpm]  Tool wear [min]  \n",
       "0                0.114522         0.007905  \n",
       "1                0.207792         0.098814  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_processed.shape)\n",
    "X_train_processed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling and oversampling\n",
    "ros = RandomOverSampler()\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train_processed, y_train)\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n",
      "(8000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adellehousker/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(15448, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adellehousker/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15448, 8)\n",
      "(15448, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n",
      "(552, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adellehousker/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "raw_pipeline = model_generator(X_train_processed, y_train, models=None)\n",
    "over_pipeline = model_generator(X_oversampled, y_oversampled, models=None)\n",
    "under_pipeline = model_generator(X_undersampled, y_undersampled, models=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99      1937\n",
      "    positive       1.00      0.19      0.32        63\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.99      0.60      0.65      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Balanced accuracy:  0.5952380952380952\n",
      "\n",
      "\n",
      "KNN ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      1.00      0.99      1937\n",
      "    positive       0.86      0.38      0.53        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.92      0.69      0.76      2000\n",
      "weighted avg       0.98      0.98      0.97      2000\n",
      "\n",
      "Balanced accuracy:  0.6894436659537331\n",
      "\n",
      "\n",
      "Decision Tree ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99      1937\n",
      "    positive       0.70      0.78      0.74        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.85      0.88      0.86      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.8834681351459874\n",
      "\n",
      "\n",
      "Random Forest ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      1.00      0.99      1937\n",
      "    positive       0.89      0.52      0.66        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.94      0.76      0.83      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.7608722373823045\n",
      "\n",
      "\n",
      "Extremely Random Trees ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      1.00      0.99      1937\n",
      "    positive       1.00      0.38      0.55        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.99      0.69      0.77      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.6904761904761905\n",
      "\n",
      "\n",
      "Gradient Boosting ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99      1937\n",
      "    positive       0.85      0.63      0.73        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.92      0.82      0.86      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.8156533995460169\n",
      "\n",
      "\n",
      "AdaBoost ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.99      0.99      1937\n",
      "    positive       0.69      0.43      0.53        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.84      0.71      0.76      2000\n",
      "weighted avg       0.97      0.98      0.97      2000\n",
      "\n",
      "Balanced accuracy:  0.711188140718342\n",
      "\n",
      "\n",
      "SVM ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      1.00      0.99      1937\n",
      "    positive       0.90      0.30      0.45        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.94      0.65      0.72      2000\n",
      "weighted avg       0.98      0.98      0.97      2000\n",
      "\n",
      "Balanced accuracy:  0.6502773885324221\n",
      "\n",
      "\n",
      "Naive Bayes ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.99      0.98      1937\n",
      "    positive       0.36      0.25      0.30        63\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.67      0.62      0.64      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "Balanced accuracy:  0.6197564553269251\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_raw = evaluate(raw_pipeline, X_test_processed, y_test)\n",
    "for model in evals_raw:\n",
    "    print(model[\"name\"], '-' * (60 - len(model)))\n",
    "    print()\n",
    "    print(model[\"report\"]) \n",
    "    print(\"Balanced accuracy: \", model[\"balanced_accuracy\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.81      0.89      1937\n",
      "    positive       0.12      0.84      0.22        63\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.56      0.82      0.55      2000\n",
      "weighted avg       0.97      0.81      0.87      2000\n",
      "\n",
      "Balanced accuracy:  0.8238357466545386\n",
      "\n",
      "\n",
      "KNN ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.98      0.98      1937\n",
      "    positive       0.39      0.37      0.38        63\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.68      0.67      0.68      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "Balanced accuracy:  0.6732469618375658\n",
      "\n",
      "\n",
      "Decision Tree ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99      1937\n",
      "    positive       0.68      0.68      0.68        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.8361072186575542\n",
      "\n",
      "\n",
      "Random Forest ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99      1937\n",
      "    positive       0.83      0.62      0.71        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.91      0.81      0.85      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.8074587604788948\n",
      "\n",
      "\n",
      "Extremely Random Trees ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      1.00      0.99      1937\n",
      "    positive       1.00      0.40      0.57        63\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.99      0.70      0.78      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Balanced accuracy:  0.6984126984126984\n",
      "\n",
      "\n",
      "Gradient Boosting ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.94      0.97      1937\n",
      "    positive       0.33      0.92      0.49        63\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.67      0.93      0.73      2000\n",
      "weighted avg       0.98      0.94      0.95      2000\n",
      "\n",
      "Balanced accuracy:  0.9303742491661955\n",
      "\n",
      "\n",
      "AdaBoost ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95      1937\n",
      "    positive       0.25      0.95      0.40        63\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.93      0.68      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Balanced accuracy:  0.9305012660717358\n",
      "\n",
      "\n",
      "SVM ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.88      0.94      1937\n",
      "    positive       0.21      0.94      0.34        63\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.60      0.91      0.64      2000\n",
      "weighted avg       0.97      0.89      0.92      2000\n",
      "\n",
      "Balanced accuracy:  0.910174463865739\n",
      "\n",
      "\n",
      "Naive Bayes ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.80      0.89      1937\n",
      "    positive       0.12      0.86      0.22        63\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.56      0.83      0.55      2000\n",
      "weighted avg       0.97      0.80      0.87      2000\n",
      "\n",
      "Balanced accuracy:  0.8297072055461316\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_over = evaluate(over_pipeline, X_test_processed, y_test)\n",
    "for model in evals_over:\n",
    "    print(model[\"name\"], '-' * (60 - len(model)))\n",
    "    print()\n",
    "    print(model[\"report\"])  \n",
    "    print(\"Balanced accuracy: \", model[\"balanced_accuracy\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.78      0.87      1937\n",
      "    positive       0.10      0.78      0.18        63\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.55      0.78      0.53      2000\n",
      "weighted avg       0.96      0.78      0.85      2000\n",
      "\n",
      "Balanced accuracy:  0.7784087649859461\n",
      "\n",
      "\n",
      "KNN ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.83      0.90      1937\n",
      "    positive       0.13      0.81      0.23        63\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.56      0.82      0.56      2000\n",
      "weighted avg       0.97      0.83      0.88      2000\n",
      "\n",
      "Balanced accuracy:  0.8182879760060968\n",
      "\n",
      "\n",
      "Decision Tree ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.89      0.94      1937\n",
      "    positive       0.22      0.92      0.35        63\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.61      0.91      0.65      2000\n",
      "weighted avg       0.97      0.89      0.92      2000\n",
      "\n",
      "Balanced accuracy:  0.9066261851496751\n",
      "\n",
      "\n",
      "Random Forest ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.89      0.94      1937\n",
      "    positive       0.21      0.95      0.35        63\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.61      0.92      0.64      2000\n",
      "weighted avg       0.97      0.89      0.92      2000\n",
      "\n",
      "Balanced accuracy:  0.91888536519409\n",
      "\n",
      "\n",
      "Extremely Random Trees ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.88      0.93      1937\n",
      "    positive       0.19      0.87      0.31        63\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.59      0.87      0.62      2000\n",
      "weighted avg       0.97      0.88      0.91      2000\n",
      "\n",
      "Balanced accuracy:  0.8740402028992633\n",
      "\n",
      "\n",
      "Gradient Boosting ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.90      0.95      1937\n",
      "    positive       0.24      0.95      0.38        63\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.62      0.93      0.67      2000\n",
      "weighted avg       0.97      0.90      0.93      2000\n",
      "\n",
      "Balanced accuracy:  0.9271455613737493\n",
      "\n",
      "\n",
      "AdaBoost ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.88      0.94      1937\n",
      "    positive       0.21      0.97      0.35        63\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.61      0.93      0.64      2000\n",
      "weighted avg       0.97      0.89      0.92      2000\n",
      "\n",
      "Balanced accuracy:  0.9257893486081405\n",
      "\n",
      "\n",
      "SVM ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.84      0.91      1937\n",
      "    positive       0.14      0.83      0.24        63\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.57      0.83      0.58      2000\n",
      "weighted avg       0.97      0.84      0.89      2000\n",
      "\n",
      "Balanced accuracy:  0.8313871065548918\n",
      "\n",
      "\n",
      "Naive Bayes ---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.75      0.86      1937\n",
      "    positive       0.10      0.87      0.19        63\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.55      0.81      0.52      2000\n",
      "weighted avg       0.97      0.76      0.84      2000\n",
      "\n",
      "Balanced accuracy:  0.8138956494661193\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evals_under = evaluate(under_pipeline, X_test_processed, y_test)\n",
    "for model in evals_under:\n",
    "    print(model[\"name\"], '-' * (60 - len(model)))\n",
    "    print()\n",
    "    print(model[\"report\"]) \n",
    "    print(\"Balanced accuracy: \", model[\"balanced_accuracy\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
